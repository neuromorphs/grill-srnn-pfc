# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/04_lmu_dms.ipynb (unless otherwise specified).

__all__ = ['LDN', 'make_ldn_B_A', 'make_lmu_dms', 'max_rates_pdf']

# Cell
import numpy as np
import nengo
import scipy.linalg
import nengo_ocl


class LDN(nengo.Process):
    def __init__(self, theta, q, size_in=1):
        self.q = q              # number of internal state dimensions per input
        self.theta = theta      # size of time window (in seconds)
        self.size_in = size_in  # number of inputs

        # Do Aaron's math to generate the matrices
        #  https://github.com/arvoelke/nengolib/blob/master/nengolib/synapses/analog.py#L536
        Q = np.arange(q, dtype=np.float64)
        R = (2*Q + 1)[:, None] / theta
        j, i = np.meshgrid(Q, Q)

        self.A = np.where(i < j, -1, (-1.)**(i-j+1)) * R
        self.B = (-1.)**Q[:, None] * R

        super().__init__(default_size_in=size_in, default_size_out=q*size_in)

    def make_step(self, shape_in, shape_out, dt, rng, state=None):
        state = np.zeros((self.q, self.size_in))

        # Handle the fact that we're discretizing the time step
        #  https://en.wikipedia.org/wiki/Discretization#Discretization_of_linear_state_space_models
        Ad = scipy.linalg.expm(self.A*dt)
        Bd = np.dot(np.dot(np.linalg.inv(self.A), (Ad-np.eye(self.q))), self.B)

        # this code will be called every timestep
        def step_legendre(t, x, state=state):
            state[:] = np.dot(Ad, state) + np.dot(Bd, x[None, :])
            return state.T.flatten()
        return step_legendre


# Cell

def make_ldn_B_A(theta=6.0, q=6, size_in=2):
    ldn = LDN(theta=theta, q=q, size_in=2)
    B_full = np.zeros((ldn.q*size_in, size_in))
    A_full = np.zeros((ldn.q*size_in, ldn.q*size_in))
    for i in range(size_in):
        B_full[ldn.q*i:ldn.q*(i+1), i:i+1] = ldn.B
        A_full[ldn.q*i:ldn.q*(i+1), ldn.q*i:ldn.q*(i+1)] = ldn.A

    return ldn, B_full, A_full


# Cell
from functools import partial
from .dms import DMSTask
import nengo_bio as bio
import nengo.dists


_rate_x = [
    3.56, 7.12, 10.68, 14.24, 17.8,
    21.36, 24.92, 28.48, 32.04, 35.6,
    39.16, 42.72, 46.28, 49.84, 53.4,
    56.96, 60.52, 64.08, 67.64, 71.2,
    74.76, 78.32, 81.88, 85.44, 89.,
    92.56, 96.12, 99.68, 103.24, 106.8,
    110.36, 113.92, 117.48, 121.04, 124.6,
    128.16, 131.72, 135.28, 138.84, 142.4,
    145.96, 149.52, 153.08, 156.64, 160.2,
    163.76, 167.32, 170.88, 174.44, 178.]
_p_max_rates = np.array([
    0.04166667, 0.15345528, 0.16971545, 0.12804878, 0.06707317,
    0.10670732, 0.06402439, 0.05284553, 0.04471545, 0.02235772,
    0.0254065 , 0.02845528, 0.0152439 , 0.01727642, 0.00914634,
    0.01219512, 0.00914634, 0.01219512, 0.00203252, 0.00101626,
    0.00101626, 0.00101626, 0.00101626, 0.00304878, 0.00101626,
    0.        , 0.00101626, 0.00101626, 0.00101626, 0.        ,
    0.00203252, 0.00101626, 0.00101626, 0.        , 0.        ,
    0.        , 0.        , 0.        , 0.        , 0.        ,
    0.        , 0.00101626, 0.        , 0.        , 0.00101626,
    0.        , 0.        , 0.        , 0.        , 0.00101626])
max_rates_pdf = nengo.dists.PDF(_rate_x, _p_max_rates / np.sum(_p_max_rates))


def make_lmu_dms(theta=6.0, q=6, n_neurons=2000, seed=1337,
                 out_transform=None,
                 n_trials_per_cond=5, trial_seed=1337,
                 tau=0.3,
                 size_in=2,
                 dales_law=False,
                 max_rates='default',
                 hetero_tau=False,
                 ssp_dim=0,
                 ssp_scale=1
                ):
    """
    Make a LMU network that performs the delayed match to sample task.
    returns the model and a dictionary of the probes.
    max_rates: one of ['default', 'uniform_low', 'data']
    hetero_tau: https://arvoelke.github.io/nengolib-docs/notebooks/examples/hetero_synapse.html
    """
    if max_rates in ['default']:
        max_rates = nengo.dists.Uniform(200, 400)
    if max_rates in ['uniform_low']:
        max_rates = nengo.dists.Uniform(20, 200)
    elif max_rates in ['data']:
        max_rates = max_rates_pdf

    ens_kwargs = {'n_neurons': n_neurons, 'seed': seed}
    if dales_law:
        Ensemble = bio.Ensemble
        ens_kwargs['p_exc'] = 0.8
    else:
        Ensemble = nengo.Ensemble

    ldn, B_full, A_full = make_ldn_B_A(theta=theta, q=q, size_in=max(ssp_dim, size_in))
    dms = DMSTask(gen_trials_per_cond=n_trials_per_cond, cond_seed=trial_seed)
    ens_kwargs['dimensions'] = ldn.q * max(ssp_dim, size_in)

    assert ssp_dim <= size_in, "ssp not yet supported"
    if ssp_dim > size_in:
        vocab = spa.Vocabulary(ssp_dim)
        vocab.populate('X.unitary().nondegenerate()')
        vocab.populate('Y.unitary().nondegenerate()')
        X = vocab.parse('X')
        Y = vocab.parse('Y')
        def convert(x):
            return (X**(x[0] * ssp_scale) + Y**(x[1] * ssp_scale)).v
    else:
        def convert(x):
            return x

    # Dummy model to get weights for ensemble's identity decoder with correct dimensionality.
    # See https://github.com/neuromorphs/grill-lmu/blob/master/weights/Connection%20Weights%20in%20Nengo.ipynb
    with nengo.Network() as dummy_model:
        ens = Ensemble(max_rates=max_rates, **ens_kwargs)
        output = nengo.Node(None, size_in=ldn.q*max(ssp_dim, size_in))
        c = nengo.Connection(ens, output)
    dummy_sim = nengo.Simulator(dummy_model)

    E = dummy_sim.data[ens].encoders
    D = dummy_sim.data[c].weights
    gain = dummy_sim.data[ens].gain
    bias = dummy_sim.data[ens].bias
    E = (gain * E.T).T
    # In the real model, when we make connections to the ensemble, we can multiply transforms
    # by this identity transform to get per-neuron weights

    # This is useful when we want to use a mixture of synaptic constants
    taus = nengo.dists.Uniform(0.01, 0.7).sample(n_neurons)

    def stim_func_hetero_synapse(x, row_ix=0):
        return E.dot(taus[row_ix] * B_full)[row_ix][None, :].dot(convert(x))

    def recurr_func_hetero_synapse(x, row_ix=0):
        return E.dot((taus[row_ix] * A_full + A_eye).dot(D))[row_ix, :][None, :].dot(convert(x))

    with nengo.Network() as model:
        # When creating the ensemble, set gain to 1 and bias to 0 because we will get them from
        # previous calculations
        ens = Ensemble(gain=np.ones(n_neurons), bias=np.zeros(n_neurons), **ens_kwargs)

        # Add back the bias
        bias_stim = nengo.Node(1)
        nengo.Connection(bias_stim, ens.neurons, transform=bias.reshape((n_neurons, 1)), synapse=None)

        # Task-stimulus input
        stim = nengo.Node(dms.stim_signal)

        if not hetero_tau:
            stim_tf = E.dot(tau * B_full)
            nengo.Connection(stim, ens.neurons, synapse=tau,
                             transform=stim_tf,
                             # function=lambda x: stim_tf.dot(convert(x))
                            )
        else:
            for ix, tau_i in enumerate(taus):
                nengo.Connection(stim, ens.neurons[ix], synapse=tau_i,
                                 transform=E.dot(tau_i * B_full)[ix, :][None, :],
                                 # function=partial(stim_func_hetero_synapse, row_ix=ix)
                                 )

        # Recurrent connection
        A_eye = np.eye(ldn.q * max(ssp_dim, size_in))
        if not hetero_tau:
            W = E.dot((tau * A_full + A_eye).dot(D))
            nengo.Connection(ens.neurons, ens.neurons, synapse=tau,
                             transform=W,
                             #function=lambda x: W.dot(convert(x))
                             )
            # bio.Connection(ens, ens, transform=W)
        else:
            for ix, tau_i in enumerate(taus):
                nengo.Connection(ens.neurons, ens.neurons[ix], synapse=tau_i,
                                 transform=E.dot((tau_i * A_full + A_eye).dot(D))[ix, :][None, :],
                                 #function=partial(recurr_func_hetero_synapse, row_ix=ix)
                                )

        output = nengo.Node(None, size_in=1)
        if out_transform is None:
            out_transform = np.ones((1, ens.n_neurons))
        nengo.Connection(ens.neurons, output,
                         transform=out_transform)

        # Sim the 'ideal' signal.
        ideal = nengo.Node(dms.ideal_signal)

        # Capture the output
        probes = {
            'ensemble': nengo.Probe(ens.neurons),
            'output': nengo.Probe(output),
            'ideal': nengo.Probe(ideal)
        }

    return model, probes
